{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "\tdef __init__(self, numChannels, classes):\n",
    "\t\t# call the parent constructor\n",
    "\t\tsuper(CNN, self).__init__()\n",
    "\t\t# initialize first set of CONV => RELU => POOL layers\n",
    "\t\tself.conv11 = Conv2d(in_channels=numChannels, out_channels=32,\n",
    "\t\t\tkernel_size=(3, 3))\n",
    "\t\tself.relu11 = ReLU()\n",
    "\t\tself.conv12 = Conv2d(in_channels=32, out_channels=32,\n",
    "\t\t\tkernel_size=(3, 3))\n",
    "\t\tself.relu12 = ReLU()\n",
    "\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "\t\t# initialize second set of CONV => RELU => POOL layers\n",
    "\t\tself.conv21 = Conv2d(in_channels=32, out_channels=64,\n",
    "\t\t\tkernel_size=(5, 5))\n",
    "\t\tself.relu21 = ReLU()\n",
    "\t\tself.conv22 = Conv2d(in_channels=64, out_channels=64,\n",
    "\t\t\tkernel_size=(3, 3))\n",
    "\t\tself.relu22 = ReLU()\n",
    "\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "\t\t# initialize third set of CONV => RELU => POOL layers\n",
    "\t\tself.conv31 = Conv2d(in_channels=64, out_channels=128,\n",
    "\t\t\tkernel_size=(5, 5))\n",
    "\t\tself.relu31 = ReLU()\n",
    "\t\tself.conv32 = Conv2d(in_channels=128, out_channels=128,\n",
    "\t\t\tkernel_size=(3, 3))\n",
    "\t\tself.relu32 = ReLU()\n",
    "\t\tself.maxpool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "\t\t# initialize first set of FC => RELU layers\n",
    "\t\tself.fc1 = Linear(in_features=3*3*128, out_features=5*128)\n",
    "\t\tself.relu3 = ReLU()\n",
    "\n",
    "\t\t# initialize second set of FC => RELU layers\n",
    "\t\tself.fc1 = Linear(in_features=5*128, out_features=5*128)\n",
    "\t\tself.relu3 = ReLU()\n",
    "\n",
    "\t\t# initialize our softmax classifier\n",
    "\t\tself.fc2 = Linear(in_features=5*128, out_features=classes)\n",
    "\t\tself.logSoftmax = LogSoftmax(dim=1) #dim=1 je ze to robi po riadkoch\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# pass the input through our first set of CONV => RELU =>\n",
    "\t\t# POOL layers\n",
    "\t\tx = self.conv11(x)\n",
    "\t\tx = self.relu11(x)\n",
    "\t\tx = self.conv12(x)\n",
    "\t\tx = self.relu12(x)\n",
    "\t\tx = self.maxpool1(x)\n",
    "\t\t# pass the output from the previous layer through the second\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "\t\tx = self.conv21(x)\n",
    "\t\tx = self.relu21(x)\n",
    "\t\tx = self.conv22(x)\n",
    "\t\tx = self.relu22(x)\n",
    "\t\tx = self.maxpool2(x)\n",
    "\t\t# pass the output from the previous layer through the third\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "\t\tx = self.conv31(x)\n",
    "\t\tx = self.relu31(x)\n",
    "\t\tx = self.conv32(x)\n",
    "\t\tx = self.relu32(x)\n",
    "\t\tx = self.maxpool3(x)\n",
    "\t\t# flatten the output from the previous layer and pass it\n",
    "\t\t# through our only set of FC => RELU layers\n",
    "\t\tx = flatten(x, 1)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu3(x)\n",
    "\t\t# pass the output to our softmax classifier to get our output\n",
    "\t\t# predictions\n",
    "\t\tx = self.fc2(x)\n",
    "\t\toutput = self.logSoftmax(x)\n",
    "\t\t# return the output predictions\n",
    "\t\treturn output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "#from pyimagesearch.lenet import LeNet\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "#from torchvision.datasets import KMNIST\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] generating the train/validation split...\n"
     ]
    }
   ],
   "source": [
    "imgs = plt.imread(\"D:\\\\skola\\\\ING\\\\LS2023\\\\NSIETE\\\\macky\\\\1.jpeg\")\n",
    "trainData = imgs\n",
    "# testData = KMNIST(root=\"data\", train=False, download=True,\n",
    "# \ttransform=ToTensor())\n",
    "# calculate the train/validation split\n",
    "print(\"[INFO] generating the train/validation split...\")\n",
    "numTrainSamples = int(len(trainData) * TRAIN_SPLIT)\n",
    "numValSamples = int(len(trainData) * VAL_SPLIT)\n",
    "(trainData, valData) = random_split(trainData,\n",
    "\t[numTrainSamples, numValSamples],\n",
    "\tgenerator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing the LeNet model...\n",
      "[INFO] training the network...\n"
     ]
    }
   ],
   "source": [
    "# initialize the LeNet model\n",
    "print(\"[INFO] initializing the LeNet model...\")\n",
    "model = CNN(\n",
    "\tnumChannels=1,\n",
    "\tclasses=len(trainData.dataset.classes)).to(device)\n",
    "# initialize our optimizer and loss function\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = nn.NLLLoss()\n",
    "# initialize a dictionary to store training history\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"train_acc\": [],\n",
    "\t\"val_loss\": [],\n",
    "\t\"val_acc\": []\n",
    "}\n",
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv11): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu11): ReLU()\n",
      "  (conv12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu12): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv21): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu21): ReLU()\n",
      "  (conv22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu22): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv31): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu31): ReLU()\n",
      "  (conv32): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu32): ReLU()\n",
      "  (maxpool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=640, out_features=640, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=640, out_features=1, bias=True)\n",
      "  (logSoftmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
